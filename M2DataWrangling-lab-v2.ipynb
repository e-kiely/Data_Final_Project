{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m156.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m156.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.5 pandas-2.2.3 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m152.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m149.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n",
      "\n",
      "=== Missing Values (Top 15 Columns with Most Missing) ===\n",
      "AINextMuch less integrated       64289\n",
      "AINextLess integrated            63082\n",
      "AINextNo change                  52939\n",
      "AINextMuch more integrated       51999\n",
      "EmbeddedAdmired                  48704\n",
      "EmbeddedWantToWorkWith           47837\n",
      "EmbeddedHaveWorkedWith           43223\n",
      "ConvertedCompYearly              42002\n",
      "AIToolNot interested in Using    41023\n",
      "AINextMore integrated            41009\n",
      "Knowledge_9                      37802\n",
      "Frequency_3                      37727\n",
      "Knowledge_8                      37679\n",
      "ProfessionalTech                 37673\n",
      "Knowledge_7                      37659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "# Summary: Data types and non-null counts\n",
    "print(\"=== Dataset Info ===\")\n",
    "df.info()\n",
    "\n",
    "# Summary: Missing values per column\n",
    "print(\"\\n=== Missing Values (Top 15 Columns with Most Missing) ===\")\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "print(missing_values.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Statistics for Numerical Columns ===\n",
      "         ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Generate basic statistics for numerical columns\n",
    "print(\"=== Basic Statistics for Numerical Columns ===\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Unique Entries in 'Country' Column ===\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    }
   ],
   "source": [
    "# Get unique values from the 'Country' column to see the distribution of data\n",
    "unique_countries = df['Country'].unique()\n",
    "print(\"=== Unique Entries in 'Country' Column ===\")\n",
    "print(unique_countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Countries:\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "\n",
      "Unique Education Levels:\n",
      "['Primary/elementary school'\n",
      " 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)'\n",
      " 'Some college/university study without earning a degree'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else' nan]\n",
      "Standardized Countries:\n",
      "['USA' 'UK' 'Canada' 'Norway' 'Uzbekistan' 'Serbia' 'Poland' 'Philippines'\n",
      " 'Bulgaria' 'Switzerland' 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine'\n",
      " 'Australia' 'Brazil' 'Japan' 'Austria' 'Iran, Islamic Republic of...'\n",
      " 'France' 'Saudi Arabia' 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden'\n",
      " 'Netherlands' 'Croatia' 'Pakistan' 'Czech Republic'\n",
      " 'Republic of North Macedonia' 'Finland' 'Slovakia' 'Russian Federation'\n",
      " 'Greece' 'Israel' 'Belgium' 'Mexico' 'United Republic of Tanzania'\n",
      " 'Hungary' 'Argentina' 'Portugal' 'Sri Lanka' 'Latvia' 'China' 'Singapore'\n",
      " 'Lebanon' 'Spain' 'South Africa' 'Lithuania' 'Viet Nam'\n",
      " 'Dominican Republic' 'Indonesia' 'Kosovo' 'Morocco' 'Taiwan' 'Georgia'\n",
      " 'San Marino' 'Tunisia' 'Bangladesh' 'Nigeria' 'Liechtenstein' 'Denmark'\n",
      " 'Ecuador' 'Malaysia' 'Albania' 'Azerbaijan' 'Chile' 'Ghana' 'Peru'\n",
      " 'Bolivia' 'Egypt' 'Luxembourg' 'Montenegro' 'Cyprus' 'Paraguay'\n",
      " 'Kazakhstan' 'Slovenia' 'Jordan' 'Venezuela, Bolivarian Republic of...'\n",
      " 'Costa Rica' 'Jamaica' 'Thailand' 'Nicaragua' 'Myanmar'\n",
      " 'Republic of Korea' 'Rwanda' 'Bosnia and Herzegovina' 'Benin'\n",
      " 'El Salvador' 'Zimbabwe' 'Afghanistan' 'Estonia' 'Malta' 'Uruguay'\n",
      " 'Belarus' 'Colombia' 'Republic of Moldova' 'Isle of Man' 'Nomadic'\n",
      " 'New Zealand' 'Palestine' 'Armenia' 'UAE' 'Maldives' 'Ethiopia' 'Fiji'\n",
      " 'Guatemala' 'Uganda' 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon'\n",
      " 'Bahamas' 'South Korea' 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "\n",
      "Standardized Education Levels:\n",
      "['Primary/elementary school' \"Bachelor's degree\" \"Master's degree\"\n",
      " 'Some college, no degree'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else' nan]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "# Check unique values in Country and EdLevel\n",
    "print(\"Unique Countries:\")\n",
    "print(df['Country'].unique())\n",
    "\n",
    "print(\"\\nUnique Education Levels:\")\n",
    "print(df['EdLevel'].unique())\n",
    "\n",
    "# Standardize Country names\n",
    "country_mapping = {\n",
    "    \"United States of America\": \"USA\",\n",
    "    \"United Kingdom of Great Britain and Northern Ireland\": \"UK\",\n",
    "    \"Republic of India\": \"India\",\n",
    "    \"United Arab Emirates\": \"UAE\"\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "df['Country'] = df['Country'].replace(country_mapping)\n",
    "\n",
    "# Standardize Education Levels\n",
    "education_mapping = {\n",
    "    \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\": \"Bachelor's degree\",\n",
    "    \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\": \"Master's degree\",\n",
    "    \"Professional degree (JD, MD, etc.)\": \"Professional degree\",\n",
    "    \"Some college/university study without earning a degree\": \"Some college, no degree\"\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "df['EdLevel'] = df['EdLevel'].replace(education_mapping)\n",
    "\n",
    "print(\"Standardized Countries:\")\n",
    "print(df['Country'].unique())\n",
    "\n",
    "print(\"\\nStandardized Education Levels:\")\n",
    "print(df['EdLevel'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New columns created from one-hot encoding:\n",
      "['Employment_Employed, full-time', 'Employment_Employed, full-time;Employed, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time;Retired', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Retired', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Retired', 'Employment_Employed, full-time;Not employed, and not looking for work', 'Employment_Employed, full-time;Not employed, but looking for work', 'Employment_Employed, full-time;Not employed, but looking for work;Employed, part-time', 'Employment_Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed', 'Employment_Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time', 'Employment_Employed, full-time;Not employed, but looking for work;Not employed, and not looking for work;Employed, part-time', 'Employment_Employed, full-time;Not employed, but looking for work;Student, part-time', 'Employment_Employed, full-time;Retired', 'Employment_Employed, full-time;Student, full-time', 'Employment_Employed, full-time;Student, full-time;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed', 'Employment_Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired', 'Employment_Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Retired', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Employed, part-time;Retired', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Student, part-time', 'Employment_Employed, full-time;Student, full-time;Not employed, but looking for work;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Student, full-time;Student, part-time', 'Employment_Employed, full-time;Student, full-time;Student, part-time;Employed, part-time', 'Employment_Employed, full-time;Student, part-time', 'Employment_Employed, full-time;Student, part-time;Employed, part-time', 'Employment_Employed, part-time', 'Employment_Employed, part-time;Retired', 'Employment_I prefer not to say', 'Employment_Independent contractor, freelancer, or self-employed', 'Employment_Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Independent contractor, freelancer, or self-employed;Employed, part-time;Retired', 'Employment_Independent contractor, freelancer, or self-employed;Not employed, and not looking for work', 'Employment_Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time', 'Employment_Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Retired', 'Employment_Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time', 'Employment_Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Retired', 'Employment_Independent contractor, freelancer, or self-employed;Retired', 'Employment_Independent contractor, freelancer, or self-employed;Student, part-time', 'Employment_Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Independent contractor, freelancer, or self-employed;Student, part-time;Retired', 'Employment_Not employed, and not looking for work', 'Employment_Not employed, and not looking for work;Employed, part-time', 'Employment_Not employed, and not looking for work;Retired', 'Employment_Not employed, and not looking for work;Student, part-time', 'Employment_Not employed, and not looking for work;Student, part-time;Employed, part-time', 'Employment_Not employed, but looking for work', 'Employment_Not employed, but looking for work;Employed, part-time', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Retired', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Retired', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Retired', 'Employment_Not employed, but looking for work;Not employed, and not looking for work', 'Employment_Not employed, but looking for work;Not employed, and not looking for work;Student, part-time', 'Employment_Not employed, but looking for work;Not employed, and not looking for work;Student, part-time;Employed, part-time', 'Employment_Not employed, but looking for work;Retired', 'Employment_Not employed, but looking for work;Student, part-time', 'Employment_Not employed, but looking for work;Student, part-time;Employed, part-time', 'Employment_Not employed, but looking for work;Student, part-time;Retired', 'Employment_Retired', 'Employment_Student, full-time', 'Employment_Student, full-time;Employed, part-time', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time;Retired', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time', 'Employment_Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time', 'Employment_Student, full-time;Not employed, and not looking for work', 'Employment_Student, full-time;Not employed, and not looking for work;Employed, part-time', 'Employment_Student, full-time;Not employed, and not looking for work;Student, part-time', 'Employment_Student, full-time;Not employed, but looking for work', 'Employment_Student, full-time;Not employed, but looking for work;Employed, part-time', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time', 'Employment_Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired', 'Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work', 'Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time', 'Employment_Student, full-time;Not employed, but looking for work;Retired', 'Employment_Student, full-time;Not employed, but looking for work;Student, part-time', 'Employment_Student, full-time;Retired', 'Employment_Student, full-time;Student, part-time', 'Employment_Student, full-time;Student, part-time;Employed, part-time', 'Employment_Student, full-time;Student, part-time;Retired', 'Employment_Student, part-time', 'Employment_Student, part-time;Employed, part-time', 'Employment_Student, part-time;Retired']\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Perform one-hot encoding on 'Employment' column\n",
    "employment_encoded = pd.get_dummies(df['Employment'], prefix='Employment')\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "df = pd.concat([df, employment_encoded], axis=1)\n",
    "\n",
    "# Optionally, drop the original 'Employment' column\n",
    "# df.drop('Employment', axis=1, inplace=True)\n",
    "\n",
    "# Display the new columns\n",
    "print(\"New columns created from one-hot encoding:\")\n",
    "print(employment_encoded.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with the highest number of missing values:\n",
      "AINextMuch less integrated    64289\n",
      "AINextLess integrated         63082\n",
      "AINextNo change               52939\n",
      "AINextMuch more integrated    51999\n",
      "EmbeddedAdmired               48704\n",
      "                              ...  \n",
      "YearsCode                      5568\n",
      "NEWSOSites                     5151\n",
      "LearnCode                      4949\n",
      "EdLevel                        4653\n",
      "AISelect                       4530\n",
      "Length: 109, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Count missing values for each column\n",
    "missing_counts = df.isnull().sum()\n",
    "\n",
    "# Filter and sort columns with at least one missing value\n",
    "missing_counts = missing_counts[missing_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "# Display the top columns with missing data\n",
    "print(\"Columns with the highest number of missing values:\")\n",
    "print(missing_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing values in 'CompTotal' with median: 110000.0\n",
      "Imputed missing values in 'WorkExp' with median: 9.0\n",
      "Imputed missing values in 'JobSatPoints_1' with median: 10.0\n",
      "Imputed missing values in 'JobSatPoints_4' with median: 0.0\n",
      "Imputed missing values in 'JobSatPoints_5' with median: 0.0\n",
      "Imputed missing values in 'JobSatPoints_6' with median: 20.0\n",
      "Imputed missing values in 'JobSatPoints_7' with median: 15.0\n",
      "Imputed missing values in 'JobSatPoints_8' with median: 10.0\n",
      "Imputed missing values in 'JobSatPoints_9' with median: 5.0\n",
      "Imputed missing values in 'JobSatPoints_10' with median: 0.0\n",
      "Imputed missing values in 'JobSatPoints_11' with median: 0.0\n",
      "Imputed missing values in 'ConvertedCompYearly' with median: 65000.0\n",
      "Imputed missing values in 'JobSat' with median: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_302/1587952717.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check for missing values in numerical columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Impute each numerical column with its median\n",
    "for col in num_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Imputed missing values in '{col}' with median: {median_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_302/2567755484.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mode_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing values in 'RemoteWork' with mode: Hybrid (some remote, some in-person)\n",
      "Imputed missing values in 'CodingActivities' with mode: Hobby\n",
      "Imputed missing values in 'EdLevel' with mode: Bachelor's degree\n",
      "Imputed missing values in 'LearnCode' with mode: Other online resources (e.g., videos, blogs, forum, online community)\n",
      "Imputed missing values in 'LearnCodeOnline' with mode: Technical documentation;Blogs;Written Tutorials;Stack Overflow\n",
      "Imputed missing values in 'TechDoc' with mode: API document(s) and/or SDK document(s);User guides or README files found in the source repository;Traditional public search engine\n",
      "Imputed missing values in 'YearsCode' with mode: 10\n",
      "Imputed missing values in 'YearsCodePro' with mode: 2\n",
      "Imputed missing values in 'DevType' with mode: Developer, full-stack\n",
      "Imputed missing values in 'OrgSize' with mode: 20 to 99 employees\n",
      "Imputed missing values in 'PurchaseInfluence' with mode: I have some influence\n",
      "Imputed missing values in 'BuyNewTool' with mode: Start a free trial;Ask developers I know/work with;Visit developer communities like Stack Overflow\n",
      "Imputed missing values in 'BuildvsBuy' with mode: Is ready-to-go but also customizable for growth and targeted use cases\n",
      "Imputed missing values in 'TechEndorse' with mode: APIs;Customization;Reputation for quality and excellence\n",
      "Imputed missing values in 'Country' with mode: USA\n",
      "Imputed missing values in 'Currency' with mode: EUR European Euro\n",
      "Imputed missing values in 'LanguageHaveWorkedWith' with mode: HTML/CSS;JavaScript;TypeScript\n",
      "Imputed missing values in 'LanguageWantToWorkWith' with mode: Python\n",
      "Imputed missing values in 'LanguageAdmired' with mode: Python\n",
      "Imputed missing values in 'DatabaseHaveWorkedWith' with mode: PostgreSQL\n",
      "Imputed missing values in 'DatabaseWantToWorkWith' with mode: PostgreSQL\n",
      "Imputed missing values in 'DatabaseAdmired' with mode: PostgreSQL\n",
      "Imputed missing values in 'PlatformHaveWorkedWith' with mode: Amazon Web Services (AWS)\n",
      "Imputed missing values in 'PlatformWantToWorkWith' with mode: Amazon Web Services (AWS)\n",
      "Imputed missing values in 'PlatformAdmired' with mode: Amazon Web Services (AWS)\n",
      "Imputed missing values in 'WebframeHaveWorkedWith' with mode: React\n",
      "Imputed missing values in 'WebframeWantToWorkWith' with mode: React\n",
      "Imputed missing values in 'WebframeAdmired' with mode: React\n",
      "Imputed missing values in 'EmbeddedHaveWorkedWith' with mode: Rasberry Pi\n",
      "Imputed missing values in 'EmbeddedWantToWorkWith' with mode: Rasberry Pi\n",
      "Imputed missing values in 'EmbeddedAdmired' with mode: Rasberry Pi\n",
      "Imputed missing values in 'MiscTechHaveWorkedWith' with mode: .NET (5+) \n",
      "Imputed missing values in 'MiscTechWantToWorkWith' with mode: .NET (5+) \n",
      "Imputed missing values in 'MiscTechAdmired' with mode: .NET (5+) \n",
      "Imputed missing values in 'ToolsTechHaveWorkedWith' with mode: Docker\n",
      "Imputed missing values in 'ToolsTechWantToWorkWith' with mode: Docker\n",
      "Imputed missing values in 'ToolsTechAdmired' with mode: Docker\n",
      "Imputed missing values in 'NEWCollabToolsHaveWorkedWith' with mode: Visual Studio Code\n",
      "Imputed missing values in 'NEWCollabToolsWantToWorkWith' with mode: Visual Studio Code\n",
      "Imputed missing values in 'NEWCollabToolsAdmired' with mode: Visual Studio Code\n",
      "Imputed missing values in 'OpSysPersonal use' with mode: Windows\n",
      "Imputed missing values in 'OpSysProfessional use' with mode: Windows\n",
      "Imputed missing values in 'OfficeStackAsyncHaveWorkedWith' with mode: Jira\n",
      "Imputed missing values in 'OfficeStackAsyncWantToWorkWith' with mode: Jira\n",
      "Imputed missing values in 'OfficeStackAsyncAdmired' with mode: Jira\n",
      "Imputed missing values in 'OfficeStackSyncHaveWorkedWith' with mode: Microsoft Teams\n",
      "Imputed missing values in 'OfficeStackSyncWantToWorkWith' with mode: Microsoft Teams\n",
      "Imputed missing values in 'OfficeStackSyncAdmired' with mode: Microsoft Teams\n",
      "Imputed missing values in 'AISearchDevHaveWorkedWith' with mode: ChatGPT\n",
      "Imputed missing values in 'AISearchDevWantToWorkWith' with mode: ChatGPT\n",
      "Imputed missing values in 'AISearchDevAdmired' with mode: ChatGPT\n",
      "Imputed missing values in 'NEWSOSites' with mode: Stack Overflow;Stack Exchange\n",
      "Imputed missing values in 'SOVisitFreq' with mode: A few times per week\n",
      "Imputed missing values in 'SOAccount' with mode: Yes\n",
      "Imputed missing values in 'SOPartFreq' with mode: Less than once per month or monthly\n",
      "Imputed missing values in 'SOHow' with mode: Quickly finding code solutions;Finding reliable guidance from community-vetted answers\n",
      "Imputed missing values in 'SOComm' with mode: No, not really\n",
      "Imputed missing values in 'AISelect' with mode: Yes\n",
      "Imputed missing values in 'AISent' with mode: Favorable\n",
      "Imputed missing values in 'AIBen' with mode: Increase productivity;Greater efficiency;Speed up learning\n",
      "Imputed missing values in 'AIAcc' with mode: Somewhat trust\n",
      "Imputed missing values in 'AIComplex' with mode: Good, but not great at handling complex tasks\n",
      "Imputed missing values in 'AIToolCurrently Using' with mode: Writing code;Debugging and getting help;Search for answers\n",
      "Imputed missing values in 'AIToolInterested in Using' with mode: Learning about a codebase\n",
      "Imputed missing values in 'AIToolNot interested in Using' with mode: Project planning\n",
      "Imputed missing values in 'AINextMuch more integrated' with mode: Search for answers\n",
      "Imputed missing values in 'AINextNo change' with mode: Writing code\n",
      "Imputed missing values in 'AINextMore integrated' with mode: Writing code\n",
      "Imputed missing values in 'AINextLess integrated' with mode: Writing code\n",
      "Imputed missing values in 'AINextMuch less integrated' with mode: Writing code\n",
      "Imputed missing values in 'AIThreat' with mode: No\n",
      "Imputed missing values in 'AIEthics' with mode: Circulating misinformation or disinformation;Missing or incorrect attribution for sources of data;Biased results that do not represent diverse viewpoints\n",
      "Imputed missing values in 'AIChallenges' with mode: Don’t trust the output or answers;AI tools lack context of codebase,  internal architecture, and/or company knowledge\n",
      "Imputed missing values in 'TBranch' with mode: Yes\n",
      "Imputed missing values in 'ICorPM' with mode: Individual contributor\n",
      "Imputed missing values in 'Knowledge_1' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_2' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_3' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_4' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_5' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_6' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_7' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_8' with mode: Agree\n",
      "Imputed missing values in 'Knowledge_9' with mode: Agree\n",
      "Imputed missing values in 'Frequency_1' with mode: 1-2 times a week\n",
      "Imputed missing values in 'Frequency_2' with mode: 1-2 times a week\n",
      "Imputed missing values in 'Frequency_3' with mode: 1-2 times a week\n",
      "Imputed missing values in 'TimeSearching' with mode: 30-60 minutes a day\n",
      "Imputed missing values in 'TimeAnswering' with mode: 15-30 minutes a day\n",
      "Imputed missing values in 'Frustration' with mode: None of these\n",
      "Imputed missing values in 'ProfessionalTech' with mode: None of these\n",
      "Imputed missing values in 'ProfessionalCloud' with mode: Hybrid (on-prem and cloud)\n",
      "Imputed missing values in 'ProfessionalQuestion' with mode: Traditional public search engine\n",
      "Imputed missing values in 'Industry' with mode: Software Development\n",
      "Imputed missing values in 'SurveyLength' with mode: Appropriate in length\n",
      "Imputed missing values in 'SurveyEase' with mode: Easy\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Select categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values with the most frequent value (mode)\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode_val = df[col].mode()[0]\n",
    "        df[col].fillna(mode_val, inplace=True)\n",
    "        print(f\"Imputed missing values in '{col}' with mode: {mode_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_MinMax\n",
      "0              65000.0                    0.003998\n",
      "1              65000.0                    0.003998\n",
      "2              65000.0                    0.003998\n",
      "3              65000.0                    0.003998\n",
      "4              65000.0                    0.003998\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Calculate min and max values\n",
    "min_val = df['ConvertedCompYearly'].min()\n",
    "max_val = df['ConvertedCompYearly'].max()\n",
    "\n",
    "# Apply Min-Max Scaling and create a new column\n",
    "df['ConvertedCompYearly_MinMax'] = (df['ConvertedCompYearly'] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Display the first few normalized values\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_MinMax']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
      "0              65000.0                11.082143\n",
      "1              65000.0                11.082143\n",
      "2              65000.0                11.082143\n",
      "3              65000.0                11.082143\n",
      "4              65000.0                11.082143\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "\n",
    "# Ensure no zero or negative values (log undefined for those)\n",
    "df['ConvertedCompYearly_Log'] = df['ConvertedCompYearly'].apply(lambda x: np.log(x) if x > 0 else np.nan)\n",
    "\n",
    "# Display the first few transformed values\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_Log']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "# Replace non-numeric values with numbers\n",
    "df['YearsCodePro'] = df['YearsCodePro'].replace({\n",
    "    'Less than 1 year': 0.5,\n",
    "    'More than 50 years': 51\n",
    "})\n",
    "\n",
    "# Convert to numeric type\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
